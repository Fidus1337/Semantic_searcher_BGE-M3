{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233c45c1-922e-4c0d-b136-d6c9b9d9b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\flays\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "============================================================\n",
      "üîç –ü–†–û–í–ï–†–ö–ê GPU\n",
      "============================================================\n",
      "\n",
      "üì¶ PyTorch version: 2.6.0+cu124\n",
      "üîß CUDA available: True\n",
      "üéÆ CUDA version: 12.4\n",
      "üìä GPU count: 1\n",
      "\n",
      "   GPU 0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "   Memory: 4.3 GB\n",
      "   Compute capability: 8.6\n",
      "\n",
      "üíæ –¢–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ VRAM:\n",
      "   Allocated: 0.00 GB\n",
      "   Cached: 0.00 GB\n",
      "\n",
      "üì¶ FAISS GPU support: False\n",
      "============================================================\n",
      "\n",
      "üìÇ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•:\n",
      "\n",
      "üîç –ê–ù–ê–õ–ò–ó –ö–û–õ–û–ù–û–ö:\n",
      "–§–∞–π–ª –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ (df_competitor): ['id', 'name']\n",
      "–ù–∞—à —Ñ–∞–π–ª (df_our):               ['id', 'name']\n",
      "------------------------------------------------------------\n",
      "============================================================\n",
      "üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ProductMatcherGPU\n",
      "============================================================\n",
      "üñ•Ô∏è  Device: cuda:0\n",
      "üéÆ GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "üíæ VRAM: 4.3 GB\n",
      "üîß FAISS-GPU: ‚ùå –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU)\n",
      "‚ö° Precision: FP16\n",
      "\n",
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ encoder: BAAI/bge-m3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoder –Ω–∞: cuda:0\n",
      "\n",
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ reranker: BAAI/bge-reranker-v2-m3\n",
      "   ‚úÖ Reranker –Ω–∞: cuda:0\n",
      "\n",
      "üíæ GPU Memory: 2.27 / 4.3 GB (reserved: 2.28 GB)\n",
      "\n",
      "‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\n",
      "============================================================\n",
      "\n",
      "======================================================================\n",
      "üöÄ –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–ï –¢–û–í–ê–†–û–í\n",
      "======================================================================\n",
      "\n",
      "üíæ GPU Memory: 2.27 / 4.3 GB (reserved: 2.28 GB)\n",
      "‚ö†Ô∏è –ö–µ—à –Ω–µ –Ω–∞–π–¥–µ–Ω\n",
      "\n",
      "============================================================\n",
      "üíæ –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ (500 —Ç–æ–≤–∞—Ä–æ–≤)\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£ –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–û—á–∏—Å—Ç–∫–∞: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 61116.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...\n",
      "   Batch size: 8 (free VRAM: 2.0 GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9489b27344294bddac6360b9068caa87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞...\n",
      "   üìä FAISS –Ω–∞ CPU\n",
      "\n",
      "4Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ...\n",
      "‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ cache_products/\n",
      "\n",
      "üíæ GPU Memory: 2.28 / 4.3 GB (reserved: 2.31 GB)\n",
      "\n",
      "üì¶ –ù–∞—à–∏ —Ç–æ–≤–∞—Ä—ã: 500\n",
      "üì¶ –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç: 500\n",
      "\n",
      "--------------------------------------------------\n",
      "üìù –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–û—á–∏—Å—Ç–∫–∞: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 50092.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...\n",
      "   Batch size: 8 (free VRAM: 2.0 GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196ae3213dc74f039457cea343878f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üîç –≠—Ç–∞–ø 2: Retrieval (—Ç–æ–ø-5)\n",
      "--------------------------------------------------\n",
      "   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è 500 —Ç–æ–≤–∞—Ä–æ–≤\n",
      "\n",
      "--------------------------------------------------\n",
      "üéØ –≠—Ç–∞–ø 3: Reranking\n",
      "--------------------------------------------------\n",
      "   Reranking 2500 –ø–∞—Ä (batch=16)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1d9193d781434092402d08d823eb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä –≠—Ç–∞–ø 4: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
      "--------------------------------------------------\n",
      "\n",
      "‚úÖ –ì–æ—Ç–æ–≤–æ!\n",
      "   –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ: 500 (100.0%)\n",
      "   –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 0 (0.0%)\n",
      "\n",
      "üíæ GPU Memory: 2.28 / 4.3 GB (reserved: 2.33 GB)\n",
      "\n",
      "======================================================================\n",
      "üìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\n",
      "======================================================================\n",
      "\n",
      "üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n",
      "   –í—Å–µ–≥–æ: 500\n",
      "   ‚úÖ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ: 500 (100.0%)\n",
      "   ‚ö†Ô∏è  –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 0 (0.0%)\n",
      "\n",
      "üìâ Rerank score:\n",
      "   –°—Ä–µ–¥–Ω–µ–µ: 0.9911\n",
      "   –ú–µ–¥–∏–∞–Ω–∞: 0.9995\n",
      "   –ú–∏–Ω/–ú–∞–∫—Å: 0.7734 / 1.0000\n",
      "\n",
      "üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:\n",
      "   >= 0.9: 489 (97.8%)\n",
      "   >= 0.7: 500 (100.0%)\n",
      "   >= 0.5: 500 (100.0%)\n",
      "   >= 0.3: 500 (100.0%)\n",
      "\n",
      "üìã –¢–æ–ø-5 –ª—É—á—à–∏—Ö:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "1. Score: 1.0000\n",
      "   –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç: Pantene ProV –®–∞–º–ø—É–Ω—å –æ–±—ä–µ–º 250–º–ª\n",
      "   –ù–∞—à:       Pantene Pro-V Shamp –æ–±—ä–µ–º 250–º–ª\n",
      "\n",
      "2. Score: 1.0000\n",
      "   –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç: L'Oreal Elseve –®–ê–ú–ü–£–ù–¨ –ø—Ä–æ—Ç–∏–≤ –≤—ã–ø–∞–¥–µ–Ω–∏—è 400–º–ª\n",
      "   –ù–∞—à:       Shamp –≠–ª—å—Å–µ–≤ - –ø—Ä–æ—Ç–∏–≤ –≤—ã–ø–∞–¥–µ–Ω–∏—è / 400–º–ª\n",
      "\n",
      "3. Score: 1.0000\n",
      "   –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç: –®–ê–ú–ü–£–ù–¨ Elseve –¥–ª—è –æ–∫—Ä–∞—à–µ–Ω–Ω—ã—Ö –≤–æ–ª–æ—Å 250–º–ª\n",
      "   –ù–∞—à:       –¥–ª—è –æ–∫—Ä–∞—à–µ–Ω–Ω—ã—Ö –≤–æ–ª–æ—Å –ó–∞—Å—ñ–± –¥–ª—è –º–∏—Ç—Ç—è –≤–æ–ª–æ—Å—Å—è Elseve 250–º–ª\n",
      "\n",
      "4. Score: 1.0000\n",
      "   –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç: –®–ê–ú–ü–£–ù–¨ SCHAUMA \"–¥–ª—è –º—É–∂—á–∏–Ω\" 400–º–ª\n",
      "   –ù–∞—à:       –¥–ª—è –º—É–∂—á–∏–Ω –®–∞–º–ø—É–Ω—å –¥–ª—è –≤–æ–ª–æ—Å—Å—è SCHAUMA 400–º–ª\n",
      "\n",
      "5. Score: 1.0000\n",
      "   –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç: –®–∞–º–ø—É–Ω—å –¥/–≤–æ–ª–æ—Å –®–∞—É–º–∞ (fresh it up) 250–º–ª\n",
      "   –ù–∞—à:       –®–∞—É–º–∞ | SHAMPOO | fresh it up | 250–º–ª\n",
      "\n",
      "üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: results_gpu_matched.csv\n",
      "üßπ –û—á–∏—Å—Ç–∫–∞ –º–æ–¥–µ–ª–µ–π...\n",
      "   GPU memory: 2.28 GB\n",
      "‚úÖ –û—á–∏—â–µ–Ω–æ\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Product Matcher v4 - GPU Optimized (RTX 3050 Ready)\n",
    "===================================================\n",
    "- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –≤—Å–µ deprecated –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è 4GB VRAM\n",
    "- FAISS –Ω–∞ CPU (GPU –≤–µ—Ä—Å–∏—è –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞)\n",
    "- Encoder + Reranker –Ω–∞ GPU\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "import faiss\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def check_gpu_status():\n",
    "    \"\"\"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ GPU\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üîç –ü–†–û–í–ï–†–ö–ê GPU\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"\\nüì¶ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"üîß CUDA available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üéÆ CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"üìä GPU count: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            print(f\"\\n   GPU {i}: {props.name}\")\n",
    "            print(f\"   Memory: {props.total_memory / 1e9:.1f} GB\")\n",
    "            print(f\"   Compute capability: {props.major}.{props.minor}\")\n",
    "        \n",
    "        print(f\"\\nüíæ –¢–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ VRAM:\")\n",
    "        print(f\"   Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        print(f\"   Cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω! –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω CPU.\")\n",
    "    \n",
    "    print(f\"\\nüì¶ FAISS GPU support: {hasattr(faiss, 'StandardGpuResources')}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return torch.cuda.is_available()\n",
    "\n",
    "\n",
    "class ProductMatcherGPU:\n",
    "    \"\"\"\n",
    "    GPU-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞—Ç—á–µ—Ä —Ç–æ–≤–∞—Ä–æ–≤:\n",
    "    1. Retrieval: BGE-M3 (GPU) + FAISS ‚Üí —Ç–æ–ø-K –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\n",
    "    2. Reranking: BGE-reranker-v2-m3 (GPU) ‚Üí –ª—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç\n",
    "    \"\"\"\n",
    "    \n",
    "    _encoder_instance = None\n",
    "    _reranker_instance = None\n",
    "    \n",
    "    def __init__(self, \n",
    "                 encoder_model: str = 'BAAI/bge-m3',\n",
    "                 reranker_model: str = 'BAAI/bge-reranker-v2-m3',\n",
    "                 cache_dir: str = './cache',\n",
    "                 use_fp16: bool = True,\n",
    "                 gpu_id: int = 0,\n",
    "                 force_gpu: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder_model: –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "            reranker_model: –ú–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "            cache_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∫–µ—à–∞\n",
    "            use_fp16: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å float16 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ VRAM\n",
    "            gpu_id: ID GPU –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "            force_gpu: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞—Ç—å GPU\n",
    "        \"\"\"\n",
    "        \n",
    "        self.gpu_available = torch.cuda.is_available()\n",
    "        self.gpu_id = gpu_id\n",
    "        \n",
    "        if force_gpu and not self.gpu_available:\n",
    "            raise RuntimeError(\"‚ùå GPU –Ω–µ –Ω–∞–π–¥–µ–Ω!\")\n",
    "        \n",
    "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        self.faiss_index: Optional[faiss.Index] = None\n",
    "        self.gpu_resources = None\n",
    "        self.eva_texts_clean: Optional[List[str]] = None\n",
    "        self.eva_df: Optional[pd.DataFrame] = None\n",
    "        \n",
    "        # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "        if self.gpu_available:\n",
    "            self.device = f'cuda:{gpu_id}'\n",
    "            torch.cuda.set_device(gpu_id)\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ProductMatcherGPU\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üñ•Ô∏è  Device: {self.device}\")\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            props = torch.cuda.get_device_properties(gpu_id)\n",
    "            self.vram_total = props.total_memory / 1e9\n",
    "            print(f\"üéÆ GPU: {props.name}\")\n",
    "            print(f\"üíæ VRAM: {self.vram_total:.1f} GB\")\n",
    "            \n",
    "            # FAISS-GPU (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "            self.faiss_gpu_available = hasattr(faiss, 'StandardGpuResources')\n",
    "            if self.faiss_gpu_available:\n",
    "                try:\n",
    "                    self.gpu_resources = faiss.StandardGpuResources()\n",
    "                    self.gpu_resources.setTempMemory(256 * 1024 * 1024)  # 256MB\n",
    "                    print(f\"üîß FAISS-GPU: ‚úÖ –î–æ—Å—Ç—É–ø–µ–Ω\")\n",
    "                except:\n",
    "                    self.faiss_gpu_available = False\n",
    "                    print(f\"üîß FAISS-GPU: ‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏\")\n",
    "            else:\n",
    "                print(f\"üîß FAISS-GPU: ‚ùå –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU)\")\n",
    "        else:\n",
    "            self.vram_total = 0\n",
    "            self.faiss_gpu_available = False\n",
    "        \n",
    "        # Dtype\n",
    "        if use_fp16 and self.gpu_available:\n",
    "            self.model_dtype = torch.float16\n",
    "            print(\"‚ö° Precision: FP16\")\n",
    "        else:\n",
    "            self.model_dtype = torch.float32\n",
    "            print(\"üìä Precision: FP32\")\n",
    "        \n",
    "        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π\n",
    "        self._load_encoder(encoder_model)\n",
    "        self._load_reranker(reranker_model)\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            self._print_gpu_memory()\n",
    "        \n",
    "        print(\"\\n‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    def _load_encoder(self, model_name: str):\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ encoder –Ω–∞ GPU\"\"\"\n",
    "        if ProductMatcherGPU._encoder_instance is None:\n",
    "            print(f\"\\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ encoder: {model_name}\")\n",
    "            \n",
    "            try:\n",
    "                # –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± —Å dtype\n",
    "                ProductMatcherGPU._encoder_instance = SentenceTransformer(\n",
    "                    model_name,\n",
    "                    device=self.device,\n",
    "                    model_kwargs={\n",
    "                        'torch_dtype': self.model_dtype,\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e1:\n",
    "                print(f\"   ‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ 1 –Ω–µ —É–¥–∞–ª–∞—Å—å: {e1}\")\n",
    "                try:\n",
    "                    # Fallback –±–µ–∑ kwargs\n",
    "                    ProductMatcherGPU._encoder_instance = SentenceTransformer(\n",
    "                        model_name,\n",
    "                        device=self.device\n",
    "                    )\n",
    "                    if self.model_dtype == torch.float16 and self.gpu_available:\n",
    "                        ProductMatcherGPU._encoder_instance.half()\n",
    "                except Exception as e2:\n",
    "                    print(f\"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e2}\")\n",
    "                    raise\n",
    "            \n",
    "            if self.gpu_available:\n",
    "                try:\n",
    "                    dev = next(ProductMatcherGPU._encoder_instance.parameters()).device\n",
    "                    print(f\"   ‚úÖ Encoder –Ω–∞: {dev}\")\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            print(\"‚úÖ Encoder —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
    "        \n",
    "        self.encoder = ProductMatcherGPU._encoder_instance\n",
    "    \n",
    "    def _load_reranker(self, model_name: str):\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ reranker –Ω–∞ GPU\"\"\"\n",
    "        if ProductMatcherGPU._reranker_instance is None:\n",
    "            print(f\"\\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ reranker: {model_name}\")\n",
    "            \n",
    "            try:\n",
    "                # –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± —Å model_kwargs\n",
    "                ProductMatcherGPU._reranker_instance = CrossEncoder(\n",
    "                    model_name,\n",
    "                    max_length=512,\n",
    "                    device=self.device,\n",
    "                    model_kwargs={'torch_dtype': self.model_dtype}\n",
    "                )\n",
    "            except Exception as e1:\n",
    "                print(f\"   ‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ 1 –Ω–µ —É–¥–∞–ª–∞—Å—å: {e1}\")\n",
    "                try:\n",
    "                    # Fallback\n",
    "                    ProductMatcherGPU._reranker_instance = CrossEncoder(\n",
    "                        model_name,\n",
    "                        max_length=512,\n",
    "                        device=self.device\n",
    "                    )\n",
    "                    if self.model_dtype == torch.float16 and self.gpu_available:\n",
    "                        ProductMatcherGPU._reranker_instance.model.half()\n",
    "                except Exception as e2:\n",
    "                    print(f\"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e2}\")\n",
    "                    raise\n",
    "            \n",
    "            if self.gpu_available:\n",
    "                try:\n",
    "                    dev = next(ProductMatcherGPU._reranker_instance.model.parameters()).device\n",
    "                    print(f\"   ‚úÖ Reranker –Ω–∞: {dev}\")\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            print(\"‚úÖ Reranker —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
    "        \n",
    "        self.reranker = ProductMatcherGPU._reranker_instance\n",
    "    \n",
    "    def _print_gpu_memory(self):\n",
    "        \"\"\"–í—ã–≤–æ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU\"\"\"\n",
    "        if self.gpu_available:\n",
    "            allocated = torch.cuda.memory_allocated(self.gpu_id) / 1e9\n",
    "            reserved = torch.cuda.memory_reserved(self.gpu_id) / 1e9\n",
    "            print(f\"\\nüíæ GPU Memory: {allocated:.2f} / {self.vram_total:.1f} GB (reserved: {reserved:.2f} GB)\")\n",
    "    \n",
    "    def _get_free_vram(self) -> float:\n",
    "        \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–±–æ–¥–Ω—É—é VRAM –≤ GB\"\"\"\n",
    "        if not self.gpu_available:\n",
    "            return 0\n",
    "        allocated = torch.cuda.memory_allocated(self.gpu_id) / 1e9\n",
    "        return self.vram_total - allocated\n",
    "    \n",
    "    @classmethod\n",
    "    def clear_models(cls):\n",
    "        \"\"\"–û—á–∏—Å—Ç–∫–∞ –º–æ–¥–µ–ª–µ–π –∏ GPU –ø–∞–º—è—Ç–∏\"\"\"\n",
    "        print(\"üßπ –û—á–∏—Å—Ç–∫–∞ –º–æ–¥–µ–ª–µ–π...\")\n",
    "        cls._encoder_instance = None\n",
    "        cls._reranker_instance = None\n",
    "        gc.collect()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "            print(f\"   GPU memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        \n",
    "        print(\"‚úÖ –û—á–∏—â–µ–Ω–æ\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
    "    # =========================================================================\n",
    "    \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text).lower().strip()\n",
    "        \n",
    "        # –ï–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è\n",
    "        replacements = [\n",
    "            (r'(\\d+)\\s*–º–ª\\b', r'\\1–º–ª'),\n",
    "            (r'(\\d+)\\s*ml\\b', r'\\1–º–ª'),\n",
    "            (r'(\\d+)\\s*–≥\\b', r'\\1–≥'),\n",
    "            (r'(\\d+)\\s*g\\b', r'\\1–≥'),\n",
    "            (r'(\\d+)\\s*–∫–≥\\b', r'\\1–∫–≥'),\n",
    "            (r'(\\d+)\\s*kg\\b', r'\\1–∫–≥'),\n",
    "            (r'(\\d+)\\s*–ª\\b', r'\\1–ª'),\n",
    "            (r'(\\d+)\\s*l\\b', r'\\1–ª'),\n",
    "            (r'(\\d+)\\s*—à—Ç\\b', r'\\1—à—Ç'),\n",
    "        ]\n",
    "        \n",
    "        for pattern, repl in replacements:\n",
    "            text = re.sub(pattern, repl, text)\n",
    "        \n",
    "        # –û—á–∏—Å—Ç–∫–∞\n",
    "        text = re.sub(r'[^\\w\\s\\-\\.,/]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def clean_texts_batch(self, texts: List[str], desc: str = \"–û—á–∏—Å—Ç–∫–∞\") -> List[str]:\n",
    "        \"\"\"–ë–∞—Ç—á-–æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤\"\"\"\n",
    "        return [self.clean_text(t) for t in tqdm(texts, desc=desc)]\n",
    "    \n",
    "    # =========================================================================\n",
    "    # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "    # =========================================================================\n",
    "    \n",
    "    def create_embeddings(self, \n",
    "                          texts: List[str], \n",
    "                          batch_size: int = 8,\n",
    "                          show_progress: bool = True) -> np.ndarray:\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (GPU)\"\"\"\n",
    "        \n",
    "        # –ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä batch_size –¥–ª—è RTX 3050\n",
    "        if self.gpu_available:\n",
    "            free_vram = self._get_free_vram()\n",
    "            if free_vram < 1.5:\n",
    "                batch_size = min(batch_size, 4)\n",
    "            elif free_vram < 2.0:\n",
    "                batch_size = min(batch_size, 8)\n",
    "            elif free_vram < 3.0:\n",
    "                batch_size = min(batch_size, 16)\n",
    "            \n",
    "            print(f\"   Batch size: {batch_size} (free VRAM: {free_vram:.1f} GB)\")\n",
    "        \n",
    "        embeddings = self.encoder.encode(\n",
    "            texts,\n",
    "            batch_size=batch_size,\n",
    "            show_progress_bar=show_progress,\n",
    "            normalize_embeddings=True,\n",
    "            convert_to_numpy=True,\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        return embeddings.astype('float32')\n",
    "    \n",
    "    # =========================================================================\n",
    "    # FAISS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def create_faiss_index(self, embeddings: np.ndarray) -> faiss.Index:\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞\"\"\"\n",
    "        dimension = embeddings.shape[1]\n",
    "        \n",
    "        # CPU –∏–Ω–¥–µ–∫—Å (–Ω–∞–¥—ë–∂–Ω–µ–µ)\n",
    "        index = faiss.IndexFlatIP(dimension)\n",
    "        index.add(embeddings)\n",
    "        \n",
    "        # GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω –∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏\n",
    "        if self.faiss_gpu_available and self.gpu_resources and self._get_free_vram() > 0.5:\n",
    "            try:\n",
    "                gpu_index = faiss.index_cpu_to_gpu(self.gpu_resources, self.gpu_id, index)\n",
    "                print(f\"   ‚úÖ FAISS –Ω–∞ GPU\")\n",
    "                return gpu_index\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è FAISS –Ω–∞ GPU –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}\")\n",
    "        \n",
    "        print(f\"   üìä FAISS –Ω–∞ CPU\")\n",
    "        return index\n",
    "    \n",
    "    def _index_to_cpu(self, index: faiss.Index) -> faiss.Index:\n",
    "        \"\"\"–ü–µ—Ä–µ–Ω–æ—Å –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞ CPU\"\"\"\n",
    "        if hasattr(faiss, 'index_gpu_to_cpu'):\n",
    "            try:\n",
    "                return faiss.index_gpu_to_cpu(index)\n",
    "            except:\n",
    "                pass\n",
    "        return index\n",
    "    \n",
    "    # =========================================================================\n",
    "    # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "    # =========================================================================\n",
    "    \n",
    "    def _get_cache_path(self, name: str) -> Path:\n",
    "        return self.cache_dir / name\n",
    "    \n",
    "    def save_index(self, \n",
    "                   df: pd.DataFrame,\n",
    "                   text_column: str,\n",
    "                   cache_name: str = 'products'):\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"üíæ –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ ({len(df)} —Ç–æ–≤–∞—Ä–æ–≤)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # –û—á–∏—Å—Ç–∫–∞\n",
    "        print(\"\\n1Ô∏è‚É£ –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤...\")\n",
    "        texts_clean = self.clean_texts_batch(df[text_column].tolist())\n",
    "        \n",
    "        # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "        print(\"\\n2Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...\")\n",
    "        embeddings = self.create_embeddings(texts_clean)\n",
    "        \n",
    "        # –ò–Ω–¥–µ–∫—Å\n",
    "        print(\"\\n3Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞...\")\n",
    "        index = self.create_faiss_index(embeddings)\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "        print(\"\\n4Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ...\")\n",
    "        cpu_index = self._index_to_cpu(index)\n",
    "        \n",
    "        np.save(self._get_cache_path(f'{cache_name}_embeddings.npy'), embeddings)\n",
    "        pd.DataFrame({'text_clean': texts_clean}).to_parquet(\n",
    "            self._get_cache_path(f'{cache_name}_texts.parquet')\n",
    "        )\n",
    "        faiss.write_index(cpu_index, str(self._get_cache_path(f'{cache_name}_index.faiss')))\n",
    "        df.to_parquet(self._get_cache_path(f'{cache_name}_products.parquet'))\n",
    "        \n",
    "        print(f\"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {self.cache_dir}/\")\n",
    "        \n",
    "        self.faiss_index = index\n",
    "        self.eva_texts_clean = texts_clean\n",
    "        self.eva_df = df\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            self._print_gpu_memory()\n",
    "        \n",
    "        return index, texts_clean\n",
    "    \n",
    "    def load_index(self, cache_name: str = 'products') -> bool:\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ –∫–µ—à–∞\"\"\"\n",
    "        paths = [\n",
    "            self._get_cache_path(f'{cache_name}_embeddings.npy'),\n",
    "            self._get_cache_path(f'{cache_name}_texts.parquet'),\n",
    "            self._get_cache_path(f'{cache_name}_index.faiss'),\n",
    "            self._get_cache_path(f'{cache_name}_products.parquet'),\n",
    "        ]\n",
    "        \n",
    "        if not all(p.exists() for p in paths):\n",
    "            print(\"‚ö†Ô∏è –ö–µ—à –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
    "            return False\n",
    "        \n",
    "        print(\"\\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –∫–µ—à–∞...\")\n",
    "        \n",
    "        self.faiss_index = faiss.read_index(str(paths[2]))\n",
    "        self.eva_texts_clean = pd.read_parquet(paths[1])['text_clean'].tolist()\n",
    "        self.eva_df = pd.read_parquet(paths[3])\n",
    "        \n",
    "        print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {self.faiss_index.ntotal} —Ç–æ–≤–∞—Ä–æ–≤\")\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            self._print_gpu_memory()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    # =========================================================================\n",
    "    # –ü–æ–∏—Å–∫ –∏ Reranking\n",
    "    # =========================================================================\n",
    "    \n",
    "    def search_candidates(self, \n",
    "                          query_embeddings: np.ndarray,\n",
    "                          top_k: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"–ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\"\"\"\n",
    "        scores, indices = self.faiss_index.search(query_embeddings.astype('float32'), top_k)\n",
    "        return indices, scores\n",
    "    \n",
    "    def rerank_batch(self,\n",
    "                     query_texts: List[str],\n",
    "                     candidates_indices: np.ndarray,\n",
    "                     batch_size: int = 16) -> List[Tuple[int, float, int]]:\n",
    "        \"\"\"–ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\"\"\"\n",
    "        \n",
    "        # –°–æ–±–∏—Ä–∞–µ–º –ø–∞—Ä—ã\n",
    "        all_pairs = []\n",
    "        pair_info = []\n",
    "        \n",
    "        for q_idx, (query, cand_indices) in enumerate(zip(query_texts, candidates_indices)):\n",
    "            for pos, idx in enumerate(cand_indices):\n",
    "                if idx >= 0:\n",
    "                    all_pairs.append([query, self.eva_texts_clean[idx]])\n",
    "                    pair_info.append((q_idx, pos, idx))\n",
    "        \n",
    "        # –ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä batch_size\n",
    "        if self.gpu_available:\n",
    "            free_vram = self._get_free_vram()\n",
    "            if free_vram < 1.0:\n",
    "                batch_size = min(batch_size, 8)\n",
    "            elif free_vram < 1.5:\n",
    "                batch_size = min(batch_size, 16)\n",
    "            elif free_vram < 2.0:\n",
    "                batch_size = min(batch_size, 32)\n",
    "        \n",
    "        print(f\"   Reranking {len(all_pairs)} –ø–∞—Ä (batch={batch_size})...\")\n",
    "        \n",
    "        # Predict\n",
    "        all_scores = self.reranker.predict(\n",
    "            all_pairs, \n",
    "            batch_size=batch_size,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º\n",
    "        query_results = {}\n",
    "        for (q_idx, pos, idx), score in zip(pair_info, all_scores):\n",
    "            if q_idx not in query_results:\n",
    "                query_results[q_idx] = []\n",
    "            query_results[q_idx].append((idx, float(score), pos))\n",
    "        \n",
    "        # –õ—É—á—à–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ\n",
    "        results = []\n",
    "        for q_idx in range(len(query_texts)):\n",
    "            if q_idx in query_results:\n",
    "                best = max(query_results[q_idx], key=lambda x: x[1])\n",
    "                results.append(best)\n",
    "            else:\n",
    "                results.append((-1, 0.0, -1))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # =========================================================================\n",
    "    # –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥\n",
    "    # =========================================================================\n",
    "    \n",
    "    def match_products(self,\n",
    "                       competitor_df: pd.DataFrame,\n",
    "                       competitor_col: str = 'name',\n",
    "                       our_df: Optional[pd.DataFrame] = None,\n",
    "                       our_col: str = 'name',\n",
    "                       top_k: int = 10,\n",
    "                       threshold: float = 0.5,\n",
    "                       encoder_batch: int = 8,\n",
    "                       reranker_batch: int = 16,\n",
    "                       use_cache: bool = True,\n",
    "                       cache_name: str = 'products') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤\n",
    "        \n",
    "        Args:\n",
    "            competitor_df: DataFrame –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞\n",
    "            competitor_col: –ö–æ–ª–æ–Ω–∫–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ç–æ–≤–∞—Ä–∞\n",
    "            our_df: –ù–∞—à DataFrame (–∏–ª–∏ None –µ—Å–ª–∏ –µ—Å—Ç—å –∫–µ—à)\n",
    "            our_col: –ö–æ–ª–æ–Ω–∫–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ç–æ–≤–∞—Ä–∞\n",
    "            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è reranking\n",
    "            threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏\n",
    "            encoder_batch: Batch size –¥–ª—è encoder\n",
    "            reranker_batch: Batch size –¥–ª—è reranker\n",
    "            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–µ—à\n",
    "            cache_name: –ò–º—è –∫–µ—à–∞\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üöÄ –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–ï –¢–û–í–ê–†–û–í\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            self._print_gpu_memory()\n",
    "        \n",
    "        # 1. –ò–Ω–¥–µ–∫—Å –Ω–∞—à–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤\n",
    "        if self.faiss_index is None:\n",
    "            if use_cache and self.load_index(cache_name):\n",
    "                pass\n",
    "            elif our_df is not None:\n",
    "                self.save_index(our_df, our_col, cache_name)\n",
    "            else:\n",
    "                raise ValueError(\"–£–∫–∞–∂–∏—Ç–µ our_df –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–µ—à\")\n",
    "        \n",
    "        print(f\"\\nüì¶ –ù–∞—à–∏ —Ç–æ–≤–∞—Ä—ã: {self.faiss_index.ntotal}\")\n",
    "        print(f\"üì¶ –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç: {len(competitor_df)}\")\n",
    "        \n",
    "        # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"üìù –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        comp_texts = competitor_df[competitor_col].tolist()\n",
    "        comp_texts_clean = self.clean_texts_batch(comp_texts, \"–û—á–∏—Å—Ç–∫–∞\")\n",
    "        \n",
    "        print(\"\\n–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...\")\n",
    "        comp_embeddings = self.create_embeddings(comp_texts_clean, batch_size=encoder_batch)\n",
    "        \n",
    "        # 3. Retrieval\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(f\"üîç –≠—Ç–∞–ø 2: Retrieval (—Ç–æ–ø-{top_k})\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        cand_indices, cand_scores = self.search_candidates(comp_embeddings, top_k)\n",
    "        print(f\"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è {len(cand_indices)} —Ç–æ–≤–∞—Ä–æ–≤\")\n",
    "        \n",
    "        # 4. Reranking\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"üéØ –≠—Ç–∞–ø 3: Reranking\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        rerank_results = self.rerank_batch(comp_texts_clean, cand_indices, batch_size=reranker_batch)\n",
    "        \n",
    "        # 5. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"üìä –≠—Ç–∞–ø 4: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É\n",
    "        if our_col in self.eva_df.columns:\n",
    "            eva_col = our_col\n",
    "        else:\n",
    "            eva_col = self.eva_df.columns[1]\n",
    "        \n",
    "        results = []\n",
    "        for comp_idx, (eva_idx, score, rank) in enumerate(rerank_results):\n",
    "            \n",
    "            status = \"matched\" if score >= threshold else \"low_confidence\"\n",
    "            \n",
    "            results.append({\n",
    "                'competitor_index': comp_idx,\n",
    "                'competitor_product': competitor_df.iloc[comp_idx][competitor_col],\n",
    "                'our_index': eva_idx if status == \"matched\" else None,\n",
    "                'our_product': self.eva_df.iloc[eva_idx][eva_col] if eva_idx >= 0 else None,\n",
    "                'retrieval_score': float(cand_scores[comp_idx][rank]) if rank >= 0 else 0.0,\n",
    "                'rerank_score': score,\n",
    "                'retrieval_rank': rank + 1 if rank >= 0 else -1,\n",
    "                'match_status': status\n",
    "            })\n",
    "        \n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "        matched = len(result_df[result_df['match_status'] == 'matched'])\n",
    "        low_conf = len(result_df[result_df['match_status'] == 'low_confidence'])\n",
    "        \n",
    "        print(f\"\\n‚úÖ –ì–æ—Ç–æ–≤–æ!\")\n",
    "        print(f\"   –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ: {matched} ({matched/len(result_df)*100:.1f}%)\")\n",
    "        print(f\"   –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {low_conf} ({low_conf/len(result_df)*100:.1f}%)\")\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            self._print_gpu_memory()\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def analyze_results(self, df: pd.DataFrame, show_examples: int = 5) -> Dict:\n",
    "        \"\"\"–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        total = len(df)\n",
    "        matched = df[df['match_status'] == 'matched']\n",
    "        low_conf = df[df['match_status'] == 'low_confidence']\n",
    "        \n",
    "        print(f\"\\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
    "        print(f\"   –í—Å–µ–≥–æ: {total}\")\n",
    "        print(f\"   ‚úÖ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ: {len(matched)} ({len(matched)/total*100:.1f}%)\")\n",
    "        print(f\"   ‚ö†Ô∏è  –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {len(low_conf)} ({len(low_conf)/total*100:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nüìâ Rerank score:\")\n",
    "        print(f\"   –°—Ä–µ–¥–Ω–µ–µ: {df['rerank_score'].mean():.4f}\")\n",
    "        print(f\"   –ú–µ–¥–∏–∞–Ω–∞: {df['rerank_score'].median():.4f}\")\n",
    "        print(f\"   –ú–∏–Ω/–ú–∞–∫—Å: {df['rerank_score'].min():.4f} / {df['rerank_score'].max():.4f}\")\n",
    "        \n",
    "        print(f\"\\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:\")\n",
    "        for t in [0.9, 0.7, 0.5, 0.3]:\n",
    "            count = len(df[df['rerank_score'] >= t])\n",
    "            print(f\"   >= {t}: {count} ({count/total*100:.1f}%)\")\n",
    "        \n",
    "        if show_examples > 0 and len(matched) > 0:\n",
    "            print(f\"\\nüìã –¢–æ–ø-{show_examples} –ª—É—á—à–∏—Ö:\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            for i, (_, row) in enumerate(matched.nlargest(show_examples, 'rerank_score').iterrows(), 1):\n",
    "                print(f\"\\n{i}. Score: {row['rerank_score']:.4f}\")\n",
    "                print(f\"   –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç: {row['competitor_product'][:65]}\")\n",
    "                print(f\"   –ù–∞—à:       {str(row['our_product'])[:65]}\")\n",
    "        \n",
    "        if show_examples > 0 and len(low_conf) > 0:\n",
    "            print(f\"\\n‚ö†Ô∏è  –•—É–¥—à–∏–µ {min(3, len(low_conf))}:\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            for i, (_, row) in enumerate(low_conf.nsmallest(min(3, len(low_conf)), 'rerank_score').iterrows(), 1):\n",
    "                print(f\"\\n{i}. Score: {row['rerank_score']:.4f}\")\n",
    "                print(f\"   –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç: {row['competitor_product'][:65]}\")\n",
    "                print(f\"   –õ—É—á—à–∏–π:    {str(row['our_product'])[:65]}\")\n",
    "        \n",
    "        return {\n",
    "            'total': total,\n",
    "            'matched': len(matched),\n",
    "            'low_confidence': len(low_conf),\n",
    "            'avg_score': df['rerank_score'].mean(),\n",
    "            'median_score': df['rerank_score'].median()\n",
    "        }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# –ë–´–°–¢–†–´–ô –ó–ê–ü–£–°–ö\n",
    "# =============================================================================\n",
    "\n",
    "def quick_match(competitor_csv: str,\n",
    "                our_csv: str,\n",
    "                output_csv: str = 'matches.csv',\n",
    "                competitor_col: str = 'name',\n",
    "                our_col: str = 'name',\n",
    "                threshold: float = 0.5,\n",
    "                top_k: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    –ë—ã—Å—Ç—Ä—ã–π –º–∞—Ç—á–∏–Ω–≥ –∏–∑ CSV —Ñ–∞–π–ª–æ–≤\n",
    "    \n",
    "    –ü—Ä–∏–º–µ—Ä:\n",
    "        results = quick_match('competitor.csv', 'our_products.csv')\n",
    "    \"\"\"\n",
    "    print(\"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "    competitor_df = pd.read_csv(competitor_csv)\n",
    "    our_df = pd.read_csv(our_csv)\n",
    "    \n",
    "    print(f\"   –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç: {len(competitor_df)} —Ç–æ–≤–∞—Ä–æ–≤\")\n",
    "    print(f\"   –ù–∞—à–∏: {len(our_df)} —Ç–æ–≤–∞—Ä–æ–≤\")\n",
    "    \n",
    "    # –ú–∞—Ç—á–µ—Ä\n",
    "    matcher = ProductMatcherGPU(use_fp16=True, force_gpu=False)\n",
    "    \n",
    "    # –ú–∞—Ç—á–∏–Ω–≥ (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è 4GB VRAM)\n",
    "    results = matcher.match_products(\n",
    "        competitor_df,\n",
    "        competitor_col=competitor_col,\n",
    "        our_df=our_df,\n",
    "        our_col=our_col,\n",
    "        top_k=top_k,\n",
    "        threshold=threshold,\n",
    "        encoder_batch=8,\n",
    "        reranker_batch=16,\n",
    "        use_cache=True\n",
    "    )\n",
    "    \n",
    "    # –ê–Ω–∞–ª–∏–∑\n",
    "    matcher.analyze_results(results)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "    results.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_csv}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å GPU –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º\n",
    "    check_gpu_status()\n",
    "\n",
    "    # 2. –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã\n",
    "    print(\"\\nüìÇ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•:\")\n",
    "    try:\n",
    "        # –ï—Å–ª–∏ —É –≤–∞—Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Ç–æ—á–∫–∞ —Å –∑–∞–ø—è—Ç–æ–π, –¥–æ–±–∞–≤—å—Ç–µ –∞—Ä–≥—É–º–µ–Ω—Ç: sep=';'\n",
    "        df_competitor = pd.read_csv(\"competitor_products.csv\") \n",
    "        df_our = pd.read_csv(\"our_products.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\")\n",
    "        print(\"   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ 'competitor_products.csv' –∏ 'our_products.csv' –ª–µ–∂–∞—Ç —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º.\")\n",
    "        exit()\n",
    "\n",
    "    # 3. –ê–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–æ–∫ (–ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω—è—Ç—å, —á—Ç–æ –≤–ø–∏—Å—ã–≤–∞—Ç—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏)\n",
    "    print(\"\\nüîç –ê–ù–ê–õ–ò–ó –ö–û–õ–û–ù–û–ö:\")\n",
    "    print(f\"–§–∞–π–ª –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞ (df_competitor): {df_competitor.columns.tolist()}\")\n",
    "    print(f\"–ù–∞—à —Ñ–∞–π–ª (df_our):               {df_our.columns.tolist()}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # =========================================================================\n",
    "    # ‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò (–û–¢–†–ï–î–ê–ö–¢–ò–†–£–ô–¢–ï –≠–¢–û–¢ –ë–õ–û–ö)\n",
    "    # =========================================================================\n",
    "    \n",
    "    # ‚ùó –í–ø–∏—à–∏—Ç–µ —Å—é–¥–∞ —Ç–æ—á–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ —Å –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è–º–∏ —Ç–æ–≤–∞—Ä–æ–≤\n",
    "    COMPETITOR_COL_NAME = 'name'   # –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ competitor_products.csv\n",
    "    OUR_COL_NAME = 'name'          # –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ our_products.csv\n",
    "\n",
    "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    USE_FP16 = True                # True –¥–ª—è RTX 3050 (—ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å)\n",
    "    BATCH_SIZE_ENCODER = 8         # –î–ª—è 4GB VRAM –ª—É—á—à–µ 4 –∏–ª–∏ 8\n",
    "    BATCH_SIZE_RERANKER = 16       # –î–ª—è 4GB VRAM –ª—É—á—à–µ 16\n",
    "    TOP_K_CANDIDATES = 5           # –°–∫–æ–ª—å–∫–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ä–µ—Ä–∞–Ω–∫–µ—Ä–æ–º\n",
    "\n",
    "    # =========================================================================\n",
    "\n",
    "    # 4. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∞\n",
    "    # –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å cache_dir, —á—Ç–æ–±—ã –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –∑–∞–ø—É—Å–∫–µ –Ω–µ —Å—á–∏—Ç–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–∞—à–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∑–∞–Ω–æ–≤–æ\n",
    "    matcher = ProductMatcherGPU(\n",
    "        use_fp16=USE_FP16, \n",
    "        cache_dir='./cache_products'\n",
    "    )\n",
    "    \n",
    "    # 5. –ó–∞–ø—É—Å–∫ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è\n",
    "    # –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ: —Å–∏–≥–Ω–∞—Ç—É—Ä–∞ –º–µ—Ç–æ–¥–∞ match_products –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –≤ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞\n",
    "    try:\n",
    "        results = matcher.match_products(\n",
    "            competitor_df=df_competitor,\n",
    "            competitor_col=COMPETITOR_COL_NAME,\n",
    "            our_df=df_our,\n",
    "            our_col=OUR_COL_NAME,\n",
    "            top_k=TOP_K_CANDIDATES,\n",
    "            threshold=0.5,             # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (0.0 - 1.0)\n",
    "            encoder_batch=BATCH_SIZE_ENCODER,\n",
    "            reranker_batch=BATCH_SIZE_RERANKER,\n",
    "            use_cache=True             # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
    "        )\n",
    "\n",
    "        # 6. –ê–Ω–∞–ª–∏–∑ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "        matcher.analyze_results(results, show_examples=5)\n",
    "        \n",
    "        output_file = 'results_gpu_matched.csv'\n",
    "        results.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {output_file}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"\\n‚ùå –û–®–ò–ë–ö–ê –ö–û–õ–û–ù–û–ö: –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ {e}\")\n",
    "        print(\"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –±–ª–æ–∫ '–ù–ê–°–¢–†–û–ô–ö–ò' –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å –≤—ã–≤–æ–¥–æ–º '–ê–ù–ê–õ–ò–ó –ö–û–õ–û–ù–û–ö'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏: {e}\")\n",
    "    finally:\n",
    "        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ GPU –≤ –∫–æ–Ω—Ü–µ —Ä–∞–±–æ—Ç—ã\n",
    "        ProductMatcherGPU.clear_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889a26c-fd1d-4cd1-9f5a-ce0df76ed9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
