{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Product Matcher v4 ‚Äî GPU Optimized\n",
    "\n",
    "**–°–∏—Å—Ç–µ–º–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π**\n",
    "\n",
    "- Encoder: `BGE-M3` (—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)\n",
    "- Reranker: `BGE-reranker-v2-m3` (–ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤)\n",
    "- Index: `FAISS` (–±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π)\n",
    "\n",
    "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è GPU —Å 4GB VRAM (RTX 3050 –∏ –ø–æ–¥–æ–±–Ω—ã—Ö)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£ Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\flays\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "import faiss\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2Ô∏è‚É£ GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîç GPU CHECK\n",
      "============================================================\n",
      "\n",
      "üì¶ PyTorch version: 2.6.0+cu124\n",
      "üîß CUDA available: True\n",
      "üéÆ CUDA version: 12.4\n",
      "üìä GPU count: 1\n",
      "\n",
      "   GPU 0: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "   Memory: 4.3 GB\n",
      "   Compute capability: 8.6\n",
      "\n",
      "üíæ Current VRAM usage:\n",
      "   Allocated: 0.00 GB\n",
      "   Cached: 0.00 GB\n",
      "\n",
      "üì¶ FAISS GPU support: False\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def check_gpu_status():\n",
    "    \"\"\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –≤—ã–≤–æ–¥ —Å—Ç–∞—Ç—É—Å–∞ GPU.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üîç GPU CHECK\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"\\nüì¶ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"üîß CUDA available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"üéÆ CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"üìä GPU count: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            print(f\"\\n   GPU {i}: {props.name}\")\n",
    "            print(f\"   Memory: {props.total_memory / 1e9:.1f} GB\")\n",
    "            print(f\"   Compute capability: {props.major}.{props.minor}\")\n",
    "        \n",
    "        print(f\"\\nüíæ Current VRAM usage:\")\n",
    "        print(f\"   Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        print(f\"   Cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  GPU unavailable! Using CPU.\")\n",
    "    \n",
    "    print(f\"\\nüì¶ FAISS GPU support: {hasattr(faiss, 'StandardGpuResources')}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return torch.cuda.is_available()\n",
    "\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "GPU_AVAILABLE = check_gpu_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3Ô∏è‚É£ ProductMatcherGPU ‚Äî Core Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductMatcherGPU:\n",
    "    \"\"\"\n",
    "    GPU-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π matcher —Ç–æ–≤–∞—Ä–æ–≤:\n",
    "    \n",
    "    Pipeline:\n",
    "        1. Retrieval: BGE-M3 (GPU) + FAISS ‚Üí Top-K –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\n",
    "        2. Reranking: BGE-reranker-v2-m3 (GPU) ‚Üí –õ—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç\n",
    "    \"\"\"\n",
    "    \n",
    "    # –°–∏–Ω–≥–ª—Ç–æ–Ω—ã –º–æ–¥–µ–ª–µ–π (—ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏)\n",
    "    _encoder_instance = None\n",
    "    _reranker_instance = None\n",
    "    \n",
    "    # =========================================================================\n",
    "    # INITIALIZATION\n",
    "    # =========================================================================\n",
    "    \n",
    "    def __init__(self, \n",
    "                 encoder_model: str = 'BAAI/bge-m3',\n",
    "                 reranker_model: str = 'BAAI/bge-reranker-v2-m3',\n",
    "                 cache_dir: str = './cache',\n",
    "                 use_fp16: bool = True,\n",
    "                 gpu_id: int = 0,\n",
    "                 force_gpu: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder_model: –ú–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "            reranker_model: –ú–æ–¥–µ–ª—å –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞\n",
    "            cache_dir: –ü–∞–ø–∫–∞ –¥–ª—è –∫—ç—à–∞\n",
    "            use_fp16: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å float16 (—ç–∫–æ–Ω–æ–º–∏—Ç VRAM)\n",
    "            gpu_id: ID GPU\n",
    "            force_gpu: –û—à–∏–±–∫–∞ –µ—Å–ª–∏ GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\n",
    "        \"\"\"\n",
    "        self.gpu_available = torch.cuda.is_available()\n",
    "        self.gpu_id = gpu_id\n",
    "        \n",
    "        if force_gpu and not self.gpu_available:\n",
    "            raise RuntimeError(\"‚ùå GPU not found!\")\n",
    "        \n",
    "        # –ê—Ç—Ä–∏–±—É—Ç—ã\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        self.faiss_index: Optional[faiss.Index] = None\n",
    "        self.gpu_resources = None\n",
    "        self.eva_texts_clean: Optional[List[str]] = None\n",
    "        self.eva_df: Optional[pd.DataFrame] = None\n",
    "        \n",
    "        # Device\n",
    "        self.device = f'cuda:{gpu_id}' if self.gpu_available else 'cpu'\n",
    "        if self.gpu_available:\n",
    "            torch.cuda.set_device(gpu_id)\n",
    "        \n",
    "        self._print_init_info(gpu_id, use_fp16)\n",
    "        \n",
    "        # Dtype\n",
    "        self.model_dtype = torch.float16 if (use_fp16 and self.gpu_available) else torch.float32\n",
    "        \n",
    "        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π\n",
    "        self._load_encoder(encoder_model)\n",
    "        self._load_reranker(reranker_model)\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            self._print_gpu_memory()\n",
    "        \n",
    "        print(\"\\n‚úÖ Initialization complete!\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    def _print_init_info(self, gpu_id: int, use_fp16: bool):\n",
    "        \"\"\"–í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"üöÄ Initializing ProductMatcherGPU\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üñ•Ô∏è  Device: {self.device}\")\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            props = torch.cuda.get_device_properties(gpu_id)\n",
    "            self.vram_total = props.total_memory / 1e9\n",
    "            print(f\"üéÆ GPU: {props.name}\")\n",
    "            print(f\"üíæ VRAM: {self.vram_total:.1f} GB\")\n",
    "            \n",
    "            # FAISS-GPU\n",
    "            self.faiss_gpu_available = hasattr(faiss, 'StandardGpuResources')\n",
    "            if self.faiss_gpu_available:\n",
    "                try:\n",
    "                    self.gpu_resources = faiss.StandardGpuResources()\n",
    "                    self.gpu_resources.setTempMemory(256 * 1024 * 1024)\n",
    "                    print(f\"üîß FAISS-GPU: ‚úÖ Available\")\n",
    "                except:\n",
    "                    self.faiss_gpu_available = False\n",
    "                    print(f\"üîß FAISS-GPU: ‚ùå Initialization error\")\n",
    "            else:\n",
    "                print(f\"üîß FAISS-GPU: ‚ùå Not installed (Using CPU)\")\n",
    "            \n",
    "            print(f\"‚ö° Precision: {'FP16' if use_fp16 else 'FP32'}\")\n",
    "        else:\n",
    "            self.vram_total = 0\n",
    "            self.faiss_gpu_available = False\n",
    "    \n",
    "    def _load_encoder(self, model_name: str):\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ encoder –Ω–∞ GPU.\"\"\"\n",
    "        if ProductMatcherGPU._encoder_instance is None:\n",
    "            print(f\"\\nüì• Loading encoder: {model_name}\")\n",
    "            \n",
    "            try:\n",
    "                ProductMatcherGPU._encoder_instance = SentenceTransformer(\n",
    "                    model_name,\n",
    "                    device=self.device,\n",
    "                    model_kwargs={'torch_dtype': self.model_dtype}\n",
    "                )\n",
    "            except Exception:\n",
    "                ProductMatcherGPU._encoder_instance = SentenceTransformer(model_name, device=self.device)\n",
    "                if self.model_dtype == torch.float16 and self.gpu_available:\n",
    "                    ProductMatcherGPU._encoder_instance.half()\n",
    "            \n",
    "            if self.gpu_available:\n",
    "                try:\n",
    "                    dev = next(ProductMatcherGPU._encoder_instance.parameters()).device\n",
    "                    print(f\"   ‚úÖ Encoder on: {dev}\")\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            print(\"‚úÖ Encoder already loaded\")\n",
    "        \n",
    "        self.encoder = ProductMatcherGPU._encoder_instance\n",
    "    \n",
    "    def _load_reranker(self, model_name: str):\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ reranker –Ω–∞ GPU.\"\"\"\n",
    "        if ProductMatcherGPU._reranker_instance is None:\n",
    "            print(f\"\\nüì• Loading reranker: {model_name}\")\n",
    "            \n",
    "            try:\n",
    "                ProductMatcherGPU._reranker_instance = CrossEncoder(\n",
    "                    model_name,\n",
    "                    max_length=512,\n",
    "                    device=self.device,\n",
    "                    model_kwargs={'torch_dtype': self.model_dtype}\n",
    "                )\n",
    "            except Exception:\n",
    "                ProductMatcherGPU._reranker_instance = CrossEncoder(\n",
    "                    model_name, max_length=512, device=self.device\n",
    "                )\n",
    "                if self.model_dtype == torch.float16 and self.gpu_available:\n",
    "                    ProductMatcherGPU._reranker_instance.model.half()\n",
    "            \n",
    "            if self.gpu_available:\n",
    "                try:\n",
    "                    dev = next(ProductMatcherGPU._reranker_instance.model.parameters()).device\n",
    "                    print(f\"   ‚úÖ Reranker on: {dev}\")\n",
    "                except:\n",
    "                    pass\n",
    "        else:\n",
    "            print(\"‚úÖ Reranker already loaded\")\n",
    "        \n",
    "        self.reranker = ProductMatcherGPU._reranker_instance\n",
    "    \n",
    "    # =========================================================================\n",
    "    # GPU UTILITIES\n",
    "    # =========================================================================\n",
    "    \n",
    "    def _print_gpu_memory(self):\n",
    "        \"\"\"–í—ã–≤–æ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –ø–∞–º—è—Ç–∏.\"\"\"\n",
    "        if self.gpu_available:\n",
    "            allocated = torch.cuda.memory_allocated(self.gpu_id) / 1e9\n",
    "            reserved = torch.cuda.memory_reserved(self.gpu_id) / 1e9\n",
    "            print(f\"\\nüíæ GPU Memory: {allocated:.2f} / {self.vram_total:.1f} GB (reserved: {reserved:.2f} GB)\")\n",
    "    \n",
    "    def _get_free_vram(self) -> float:\n",
    "        \"\"\"–ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–±–æ–¥–Ω—É—é VRAM –≤ GB.\"\"\"\n",
    "        if not self.gpu_available:\n",
    "            return 0\n",
    "        allocated = torch.cuda.memory_allocated(self.gpu_id) / 1e9\n",
    "        return self.vram_total - allocated\n",
    "    \n",
    "    @classmethod\n",
    "    def clear_models(cls):\n",
    "        \"\"\"–û—á–∏—Å—Ç–∫–∞ –º–æ–¥–µ–ª–µ–π –∏ GPU –ø–∞–º—è—Ç–∏.\"\"\"\n",
    "        print(\"üßπ Clearing models...\")\n",
    "        cls._encoder_instance = None\n",
    "        cls._reranker_instance = None\n",
    "        gc.collect()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "            print(f\"   GPU memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        \n",
    "        print(\"‚úÖ Cleared\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # TEXT CLEANING\n",
    "    # =========================================================================\n",
    "    \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Ç–æ–≤–∞—Ä–∞.\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text).lower().strip()\n",
    "        \n",
    "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –µ–¥–∏–Ω–∏—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è\n",
    "        replacements = [\n",
    "            (r'(\\d+)\\s*–º–ª\\b', r'\\1–º–ª'),\n",
    "            (r'(\\d+)\\s*ml\\b', r'\\1–º–ª'),\n",
    "            (r'(\\d+)\\s*–≥\\b', r'\\1–≥'),\n",
    "            (r'(\\d+)\\s*g\\b', r'\\1–≥'),\n",
    "            (r'(\\d+)\\s*–∫–≥\\b', r'\\1–∫–≥'),\n",
    "            (r'(\\d+)\\s*kg\\b', r'\\1–∫–≥'),\n",
    "            (r'(\\d+)\\s*–ª\\b', r'\\1–ª'),\n",
    "            (r'(\\d+)\\s*l\\b', r'\\1–ª'),\n",
    "            (r'(\\d+)\\s*—à—Ç\\b', r'\\1—à—Ç'),\n",
    "        ]\n",
    "        \n",
    "        for pattern, repl in replacements:\n",
    "            text = re.sub(pattern, repl, text)\n",
    "        \n",
    "        # –û—á–∏—Å—Ç–∫–∞ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤\n",
    "        text = re.sub(r'[^\\w\\s\\-\\.,/]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def clean_texts_batch(self, texts: List[str], desc: str = \"Cleaning\") -> List[str]:\n",
    "        \"\"\"–ë–∞—Ç—á–µ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤.\"\"\"\n",
    "        return [self.clean_text(t) for t in tqdm(texts, desc=desc)]\n",
    "    \n",
    "    # =========================================================================\n",
    "    # EMBEDDINGS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def create_embeddings(self, \n",
    "                          texts: List[str], \n",
    "                          batch_size: int = 8,\n",
    "                          show_progress: bool = True) -> np.ndarray:\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (GPU).\"\"\"\n",
    "        \n",
    "        # –ê–≤—Ç–æ-–ø–æ–¥–±–æ—Ä batch_size –ø–æ–¥ VRAM\n",
    "        if self.gpu_available:\n",
    "            free_vram = self._get_free_vram()\n",
    "            if free_vram < 1.5:\n",
    "                batch_size = min(batch_size, 4)\n",
    "            elif free_vram < 2.0:\n",
    "                batch_size = min(batch_size, 8)\n",
    "            elif free_vram < 3.0:\n",
    "                batch_size = min(batch_size, 16)\n",
    "            \n",
    "            print(f\"   Batch size: {batch_size} (free VRAM: {free_vram:.1f} GB)\")\n",
    "        \n",
    "        embeddings = self.encoder.encode(\n",
    "            texts,\n",
    "            batch_size=batch_size,\n",
    "            show_progress_bar=show_progress,\n",
    "            normalize_embeddings=True,\n",
    "            convert_to_numpy=True,\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        return embeddings.astype('float32')\n",
    "    \n",
    "    # =========================================================================\n",
    "    # FAISS INDEX\n",
    "    # =========================================================================\n",
    "    \n",
    "    def create_faiss_index(self, embeddings: np.ndarray) -> faiss.Index:\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞.\"\"\"\n",
    "        dimension = embeddings.shape[1]\n",
    "        \n",
    "        # CPU –∏–Ω–¥–µ–∫—Å (–±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω—ã–π)\n",
    "        index = faiss.IndexFlatIP(dimension)\n",
    "        index.add(embeddings)\n",
    "        \n",
    "        # GPU –∏–Ω–¥–µ–∫—Å –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω\n",
    "        if self.faiss_gpu_available and self.gpu_resources and self._get_free_vram() > 0.5:\n",
    "            try:\n",
    "                gpu_index = faiss.index_cpu_to_gpu(self.gpu_resources, self.gpu_id, index)\n",
    "                print(f\"   ‚úÖ FAISS on GPU\")\n",
    "                return gpu_index\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è FAISS on GPU failed: {e}\")\n",
    "        \n",
    "        print(f\"   üìä FAISS on CPU\")\n",
    "        return index\n",
    "    \n",
    "    def _index_to_cpu(self, index: faiss.Index) -> faiss.Index:\n",
    "        \"\"\"–ü–µ—Ä–µ–Ω–æ—Å –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞ CPU.\"\"\"\n",
    "        if hasattr(faiss, 'index_gpu_to_cpu'):\n",
    "            try:\n",
    "                return faiss.index_gpu_to_cpu(index)\n",
    "            except:\n",
    "                pass\n",
    "        return index\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CACHE MANAGEMENT\n",
    "    # =========================================================================\n",
    "    \n",
    "    def _get_cache_path(self, name: str) -> Path:\n",
    "        return self.cache_dir / name\n",
    "    \n",
    "    def save_index(self, \n",
    "                   df: pd.DataFrame,\n",
    "                   text_column: str,\n",
    "                   cache_name: str = 'products'):\n",
    "        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"üíæ Creating Index ({len(df)} items)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(\"\\n1Ô∏è‚É£ Cleaning texts...\")\n",
    "        texts_clean = self.clean_texts_batch(df[text_column].tolist())\n",
    "        \n",
    "        print(\"\\n2Ô∏è‚É£ Creating embeddings...\")\n",
    "        embeddings = self.create_embeddings(texts_clean)\n",
    "        \n",
    "        print(\"\\n3Ô∏è‚É£ Creating FAISS index...\")\n",
    "        index = self.create_faiss_index(embeddings)\n",
    "        \n",
    "        print(\"\\n4Ô∏è‚É£ Saving...\")\n",
    "        cpu_index = self._index_to_cpu(index)\n",
    "        \n",
    "        np.save(self._get_cache_path(f'{cache_name}_embeddings.npy'), embeddings)\n",
    "        pd.DataFrame({'text_clean': texts_clean}).to_parquet(\n",
    "            self._get_cache_path(f'{cache_name}_texts.parquet')\n",
    "        )\n",
    "        faiss.write_index(cpu_index, str(self._get_cache_path(f'{cache_name}_index.faiss')))\n",
    "        df.to_parquet(self._get_cache_path(f'{cache_name}_products.parquet'))\n",
    "        \n",
    "        print(f\"‚úÖ Saved to {self.cache_dir}/\")\n",
    "        \n",
    "        self.faiss_index = index\n",
    "        self.eva_texts_clean = texts_clean\n",
    "        self.eva_df = df\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            self._print_gpu_memory()\n",
    "        \n",
    "        return index, texts_clean\n",
    "    \n",
    "    def load_index(self, cache_name: str = 'products') -> bool:\n",
    "        \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ –∫—ç—à–∞.\"\"\"\n",
    "        paths = [\n",
    "            self._get_cache_path(f'{cache_name}_embeddings.npy'),\n",
    "            self._get_cache_path(f'{cache_name}_texts.parquet'),\n",
    "            self._get_cache_path(f'{cache_name}_index.faiss'),\n",
    "            self._get_cache_path(f'{cache_name}_products.parquet'),\n",
    "        ]\n",
    "        \n",
    "        if not all(p.exists() for p in paths):\n",
    "            print(\"‚ö†Ô∏è Cache not found\")\n",
    "            return False\n",
    "        \n",
    "        print(\"\\nüìÇ Loading from cache...\")\n",
    "        \n",
    "        self.faiss_index = faiss.read_index(str(paths[2]))\n",
    "        self.eva_texts_clean = pd.read_parquet(paths[1])['text_clean'].tolist()\n",
    "        self.eva_df = pd.read_parquet(paths[3])\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {self.faiss_index.ntotal} items\")\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            self._print_gpu_memory()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    # =========================================================================\n",
    "    # SEARCH & RERANKING\n",
    "    # =========================================================================\n",
    "    \n",
    "    def search_candidates(self, \n",
    "                          query_embeddings: np.ndarray,\n",
    "                          top_k: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"–ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.\"\"\"\n",
    "        scores, indices = self.faiss_index.search(query_embeddings.astype('float32'), top_k)\n",
    "        return indices, scores\n",
    "    \n",
    "    def rerank_batch(self,\n",
    "                     query_texts: List[str],\n",
    "                     candidates_indices: np.ndarray,\n",
    "                     batch_size: int = 16) -> List[Tuple[int, float, int]]:\n",
    "        \"\"\"–†–µ—Ä–∞–Ω–∫–∏–Ω–≥ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.\"\"\"\n",
    "        \n",
    "        # –°–±–æ—Ä –ø–∞—Ä\n",
    "        all_pairs = []\n",
    "        pair_info = []\n",
    "        \n",
    "        for q_idx, (query, cand_indices) in enumerate(zip(query_texts, candidates_indices)):\n",
    "            for pos, idx in enumerate(cand_indices):\n",
    "                if idx >= 0:\n",
    "                    all_pairs.append([query, self.eva_texts_clean[idx]])\n",
    "                    pair_info.append((q_idx, pos, idx))\n",
    "        \n",
    "        # –ê–≤—Ç–æ-–ø–æ–¥–±–æ—Ä batch_size\n",
    "        if self.gpu_available:\n",
    "            free_vram = self._get_free_vram()\n",
    "            if free_vram < 1.0:\n",
    "                batch_size = min(batch_size, 8)\n",
    "            elif free_vram < 1.5:\n",
    "                batch_size = min(batch_size, 16)\n",
    "            elif free_vram < 2.0:\n",
    "                batch_size = min(batch_size, 32)\n",
    "        \n",
    "        print(f\"   Reranking {len(all_pairs)} pairs (batch={batch_size})...\")\n",
    "        \n",
    "        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "        all_scores = self.reranker.predict(\n",
    "            all_pairs, \n",
    "            batch_size=batch_size,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞\n",
    "        query_results = {}\n",
    "        for (q_idx, pos, idx), score in zip(pair_info, all_scores):\n",
    "            if q_idx not in query_results:\n",
    "                query_results[q_idx] = []\n",
    "            query_results[q_idx].append((idx, float(score), pos))\n",
    "        \n",
    "        # –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ\n",
    "        results = []\n",
    "        for q_idx in range(len(query_texts)):\n",
    "            if q_idx in query_results:\n",
    "                best = max(query_results[q_idx], key=lambda x: x[1])\n",
    "                results.append(best)\n",
    "            else:\n",
    "                results.append((-1, 0.0, -1))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    # =========================================================================\n",
    "    # MAIN MATCHING METHOD\n",
    "    # =========================================================================\n",
    "    \n",
    "    def match_products(self,\n",
    "                       competitor_df: pd.DataFrame,\n",
    "                       competitor_col: str = 'name',\n",
    "                       our_df: Optional[pd.DataFrame] = None,\n",
    "                       our_col: str = 'name',\n",
    "                       top_k: int = 10,\n",
    "                       threshold: float = 0.5,\n",
    "                       encoder_batch: int = 8,\n",
    "                       reranker_batch: int = 16,\n",
    "                       use_cache: bool = True,\n",
    "                       cache_name: str = 'products') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤.\n",
    "        \n",
    "        Args:\n",
    "            competitor_df: DataFrame –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞\n",
    "            competitor_col: –ö–æ–ª–æ–Ω–∫–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ç–æ–≤–∞—Ä–∞\n",
    "            our_df: –ù–∞—à DataFrame (–∏–ª–∏ None –µ—Å–ª–∏ –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω)\n",
    "            our_col: –ö–æ–ª–æ–Ω–∫–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ç–æ–≤–∞—Ä–∞\n",
    "            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞\n",
    "            threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏\n",
    "            encoder_batch: Batch size –¥–ª—è encoder\n",
    "            reranker_batch: Batch size –¥–ª—è reranker\n",
    "            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à\n",
    "            cache_name: –ò–º—è –∫—ç—à–∞\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üöÄ MATCHING PRODUCTS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            self._print_gpu_memory()\n",
    "        \n",
    "        # 1. –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–∞—à–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤\n",
    "        if self.faiss_index is None:\n",
    "            if use_cache and self.load_index(cache_name):\n",
    "                pass\n",
    "            elif our_df is not None:\n",
    "                self.save_index(our_df, our_col, cache_name)\n",
    "            else:\n",
    "                raise ValueError(\"Provide our_df or use cache\")\n",
    "        \n",
    "        print(f\"\\nüì¶ Our products: {self.faiss_index.ntotal}\")\n",
    "        print(f\"üì¶ Competitor products: {len(competitor_df)}\")\n",
    "        \n",
    "        # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"üìù Stage 1: Preparing competitor products\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        comp_texts = competitor_df[competitor_col].tolist()\n",
    "        comp_texts_clean = self.clean_texts_batch(comp_texts, \"Cleaning\")\n",
    "        \n",
    "        print(\"\\nCreating embeddings...\")\n",
    "        comp_embeddings = self.create_embeddings(comp_texts_clean, batch_size=encoder_batch)\n",
    "        \n",
    "        # 3. Retrieval\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(f\"üîç Stage 2: Retrieval (Top-{top_k})\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        cand_indices, cand_scores = self.search_candidates(comp_embeddings, top_k)\n",
    "        print(f\"   ‚úÖ Candidates found for {len(cand_indices)} items\")\n",
    "        \n",
    "        # 4. Reranking\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"üéØ Stage 3: Reranking\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        rerank_results = self.rerank_batch(comp_texts_clean, cand_indices, batch_size=reranker_batch)\n",
    "        \n",
    "        # 5. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"üìä Stage 4: Building results\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        eva_col = our_col if our_col in self.eva_df.columns else self.eva_df.columns[1]\n",
    "        \n",
    "        results = []\n",
    "        for comp_idx, (eva_idx, score, rank) in enumerate(rerank_results):\n",
    "            status = \"matched\" if score >= threshold else \"low_confidence\"\n",
    "            \n",
    "            results.append({\n",
    "                'competitor_index': comp_idx,\n",
    "                'competitor_product': competitor_df.iloc[comp_idx][competitor_col],\n",
    "                'our_index': eva_idx if status == \"matched\" else None,\n",
    "                'our_product': self.eva_df.iloc[eva_idx][eva_col] if eva_idx >= 0 else None,\n",
    "                'retrieval_score': float(cand_scores[comp_idx][rank]) if rank >= 0 else 0.0,\n",
    "                'rerank_score': score,\n",
    "                'retrieval_rank': rank + 1 if rank >= 0 else -1,\n",
    "                'match_status': status\n",
    "            })\n",
    "        \n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "        matched = len(result_df[result_df['match_status'] == 'matched'])\n",
    "        low_conf = len(result_df[result_df['match_status'] == 'low_confidence'])\n",
    "        \n",
    "        print(f\"\\n‚úÖ Done!\")\n",
    "        print(f\"   Matched: {matched} ({matched/len(result_df)*100:.1f}%)\")\n",
    "        print(f\"   Low confidence: {low_conf} ({low_conf/len(result_df)*100:.1f}%)\")\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            self._print_gpu_memory()\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    # =========================================================================\n",
    "    # ANALYSIS\n",
    "    # =========================================================================\n",
    "    \n",
    "    def analyze_results(self, df: pd.DataFrame, show_examples: int = 5) -> Dict:\n",
    "        \"\"\"–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"üìä RESULTS ANALYSIS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        total = len(df)\n",
    "        matched = df[df['match_status'] == 'matched']\n",
    "        low_conf = df[df['match_status'] == 'low_confidence']\n",
    "        \n",
    "        print(f\"\\nüìà Statistics:\")\n",
    "        print(f\"   Total: {total}\")\n",
    "        print(f\"   ‚úÖ Matched: {len(matched)} ({len(matched)/total*100:.1f}%)\")\n",
    "        print(f\"   ‚ö†Ô∏è  Low confidence: {len(low_conf)} ({len(low_conf)/total*100:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nüìâ Rerank score:\")\n",
    "        print(f\"   Mean: {df['rerank_score'].mean():.4f}\")\n",
    "        print(f\"   Median: {df['rerank_score'].median():.4f}\")\n",
    "        print(f\"   Min/Max: {df['rerank_score'].min():.4f} / {df['rerank_score'].max():.4f}\")\n",
    "        \n",
    "        print(f\"\\nüìä Distribution:\")\n",
    "        for t in [0.9, 0.7, 0.5, 0.3]:\n",
    "            count = len(df[df['rerank_score'] >= t])\n",
    "            print(f\"   >= {t}: {count} ({count/total*100:.1f}%)\")\n",
    "        \n",
    "        if show_examples > 0 and len(matched) > 0:\n",
    "            print(f\"\\nüìã Top-{show_examples} Best Matches:\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            for i, (_, row) in enumerate(matched.nlargest(show_examples, 'rerank_score').iterrows(), 1):\n",
    "                print(f\"\\n{i}. Score: {row['rerank_score']:.4f}\")\n",
    "                print(f\"   Competitor: {row['competitor_product'][:65]}\")\n",
    "                print(f\"   Our:        {str(row['our_product'])[:65]}\")\n",
    "        \n",
    "        if show_examples > 0 and len(low_conf) > 0:\n",
    "            print(f\"\\n‚ö†Ô∏è  Worst {min(3, len(low_conf))}:\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            for i, (_, row) in enumerate(low_conf.nsmallest(min(3, len(low_conf)), 'rerank_score').iterrows(), 1):\n",
    "                print(f\"\\n{i}. Score: {row['rerank_score']:.4f}\")\n",
    "                print(f\"   Competitor: {row['competitor_product'][:65]}\")\n",
    "                print(f\"   Best Guess: {str(row['our_product'])[:65]}\")\n",
    "        \n",
    "        return {\n",
    "            'total': total,\n",
    "            'matched': len(matched),\n",
    "            'low_confidence': len(low_conf),\n",
    "            'avg_score': df['rerank_score'].mean(),\n",
    "            'median_score': df['rerank_score'].median()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4Ô∏è‚É£ Quick Start Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_match(competitor_csv: str,\n",
    "                our_csv: str,\n",
    "                output_csv: str = 'matches.csv',\n",
    "                competitor_col: str = 'name',\n",
    "                our_col: str = 'name',\n",
    "                threshold: float = 0.5,\n",
    "                top_k: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    –ë—ã—Å—Ç—Ä–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–∑ CSV —Ñ–∞–π–ª–æ–≤.\n",
    "    \n",
    "    –ü—Ä–∏–º–µ—Ä:\n",
    "        results = quick_match('competitor.csv', 'our_products.csv')\n",
    "    \"\"\"\n",
    "    print(\"üìÇ Loading data...\")\n",
    "    competitor_df = pd.read_csv(competitor_csv)\n",
    "    our_df = pd.read_csv(our_csv)\n",
    "    \n",
    "    print(f\"   Competitor: {len(competitor_df)} items\")\n",
    "    print(f\"   Our: {len(our_df)} items\")\n",
    "    \n",
    "    matcher = ProductMatcherGPU(use_fp16=True, force_gpu=False)\n",
    "    \n",
    "    results = matcher.match_products(\n",
    "        competitor_df,\n",
    "        competitor_col=competitor_col,\n",
    "        our_df=our_df,\n",
    "        our_col=our_col,\n",
    "        top_k=top_k,\n",
    "        threshold=threshold,\n",
    "        encoder_batch=8,\n",
    "        reranker_batch=16,\n",
    "        use_cache=True\n",
    "    )\n",
    "    \n",
    "    matcher.analyze_results(results)\n",
    "    \n",
    "    results.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\nüíæ Saved: {output_csv}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5Ô∏è‚É£ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò (–†–ï–î–ê–ö–¢–ò–†–£–ô –ó–î–ï–°–¨)\n",
    "# =============================================================================\n",
    "\n",
    "# –§–∞–π–ª—ã\n",
    "COMPETITOR_FILE = \"competitor_products.csv\"\n",
    "OUR_FILE = \"our_products.csv\"\n",
    "OUTPUT_FILE = \"results_gpu_matched.csv\"\n",
    "\n",
    "# –ö–æ–ª–æ–Ω–∫–∏ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ —Ç–æ–≤–∞—Ä–æ–≤\n",
    "COMPETITOR_COL_NAME = 'name'\n",
    "OUR_COL_NAME = 'name'\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–¥–ª—è 4GB VRAM)\n",
    "USE_FP16 = True                # FP16 —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å\n",
    "BATCH_SIZE_ENCODER = 8         # 4-8 –¥–ª—è 4GB VRAM\n",
    "BATCH_SIZE_RERANKER = 16       # 16 –¥–ª—è 4GB VRAM\n",
    "TOP_K_CANDIDATES = 5           # –ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞\n",
    "THRESHOLD = 0.5                # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (0.0 - 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6Ô∏è‚É£ Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ LOADING DATA:\n",
      "‚úÖ Competitor: 500 items\n",
      "‚úÖ Our: 500 items\n"
     ]
    }
   ],
   "source": [
    "print(\"üìÇ LOADING DATA:\")\n",
    "\n",
    "try:\n",
    "    # –î–ª—è CSV —Å —Ç–æ—á–∫–æ–π —Å –∑–∞–ø—è—Ç–æ–π: –¥–æ–±–∞–≤—å sep=';'\n",
    "    df_competitor = pd.read_csv(COMPETITOR_FILE)\n",
    "    df_our = pd.read_csv(OUR_FILE)\n",
    "    \n",
    "    print(f\"‚úÖ Competitor: {len(df_competitor)} items\")\n",
    "    print(f\"‚úÖ Our: {len(df_our)} items\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"   –£–±–µ–¥–∏—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–∫—Ä–∏–ø—Ç–∞.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç COLUMN ANALYSIS:\n",
      "   Competitor: ['id', 'name']\n",
      "   Our:        ['id', 'name']\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫\n",
    "print(\"üîç COLUMN ANALYSIS:\")\n",
    "print(f\"   Competitor: {df_competitor.columns.tolist()}\")\n",
    "print(f\"   Our:        {df_our.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7Ô∏è‚É£ Initialize Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ Initializing ProductMatcherGPU\n",
      "============================================================\n",
      "üñ•Ô∏è  Device: cuda:0\n",
      "üéÆ GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "üíæ VRAM: 4.3 GB\n",
      "üîß FAISS-GPU: ‚ùå Not installed (Using CPU)\n",
      "‚ö° Precision: FP16\n",
      "\n",
      "üì• Loading encoder: BAAI/bge-m3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Encoder on: cuda:0\n",
      "\n",
      "üì• Loading reranker: BAAI/bge-reranker-v2-m3\n",
      "   ‚úÖ Reranker on: cuda:0\n",
      "\n",
      "üíæ GPU Memory: 2.27 / 4.3 GB (reserved: 2.28 GB)\n",
      "\n",
      "‚úÖ Initialization complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "matcher = ProductMatcherGPU(\n",
    "    use_fp16=USE_FP16,\n",
    "    cache_dir='./cache_products'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8Ô∏è‚É£ Run Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ MATCHING PRODUCTS\n",
      "======================================================================\n",
      "\n",
      "üíæ GPU Memory: 2.27 / 4.3 GB (reserved: 2.28 GB)\n",
      "\n",
      "üìÇ Loading from cache...\n",
      "‚úÖ Loaded 500 items\n",
      "\n",
      "üíæ GPU Memory: 2.27 / 4.3 GB (reserved: 2.28 GB)\n",
      "\n",
      "üì¶ Our products: 500\n",
      "üì¶ Competitor products: 500\n",
      "\n",
      "--------------------------------------------------\n",
      "üìù Stage 1: Preparing competitor products\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:00<00:00, 27845.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating embeddings...\n",
      "   Batch size: 8 (free VRAM: 2.0 GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb34f93f3c584ad39b98ff16bf38fe48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üîç Stage 2: Retrieval (Top-5)\n",
      "--------------------------------------------------\n",
      "   ‚úÖ Candidates found for 500 items\n",
      "\n",
      "--------------------------------------------------\n",
      "üéØ Stage 3: Reranking\n",
      "--------------------------------------------------\n",
      "   Reranking 2500 pairs (batch=16)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6103d4fd668b4e0faef9757ed164c2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "üìä Stage 4: Building results\n",
      "--------------------------------------------------\n",
      "\n",
      "‚úÖ Done!\n",
      "   Matched: 500 (100.0%)\n",
      "   Low confidence: 0 (0.0%)\n",
      "\n",
      "üíæ GPU Memory: 2.28 / 4.3 GB (reserved: 2.33 GB)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    results = matcher.match_products(\n",
    "        competitor_df=df_competitor,\n",
    "        competitor_col=COMPETITOR_COL_NAME,\n",
    "        our_df=df_our,\n",
    "        our_col=OUR_COL_NAME,\n",
    "        top_k=TOP_K_CANDIDATES,\n",
    "        threshold=THRESHOLD,\n",
    "        encoder_batch=BATCH_SIZE_ENCODER,\n",
    "        reranker_batch=BATCH_SIZE_RERANKER,\n",
    "        use_cache=True\n",
    "    )\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(f\"\\n‚ùå COLUMN ERROR: Column not found {e}\")\n",
    "    print(\"   –ü—Ä–æ–≤–µ—Ä—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ COMPETITOR_COL_NAME –∏ OUR_COL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9Ô∏è‚É£ Analyze & Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä RESULTS ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üìà Statistics:\n",
      "   Total: 500\n",
      "   ‚úÖ Matched: 500 (100.0%)\n",
      "   ‚ö†Ô∏è  Low confidence: 0 (0.0%)\n",
      "\n",
      "üìâ Rerank score:\n",
      "   Mean: 0.9911\n",
      "   Median: 0.9995\n",
      "   Min/Max: 0.7734 / 1.0000\n",
      "\n",
      "üìä Distribution:\n",
      "   >= 0.9: 489 (97.8%)\n",
      "   >= 0.7: 500 (100.0%)\n",
      "   >= 0.5: 500 (100.0%)\n",
      "   >= 0.3: 500 (100.0%)\n",
      "\n",
      "üìã Top-5 Best Matches:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "1. Score: 1.0000\n",
      "   Competitor: Pantene ProV –®–∞–º–ø—É–Ω—å –æ–±—ä–µ–º 250–º–ª\n",
      "   Our:        Pantene Pro-V Shamp –æ–±—ä–µ–º 250–º–ª\n",
      "\n",
      "2. Score: 1.0000\n",
      "   Competitor: L'Oreal Elseve –®–ê–ú–ü–£–ù–¨ –ø—Ä–æ—Ç–∏–≤ –≤—ã–ø–∞–¥–µ–Ω–∏—è 400–º–ª\n",
      "   Our:        Shamp –≠–ª—å—Å–µ–≤ - –ø—Ä–æ—Ç–∏–≤ –≤—ã–ø–∞–¥–µ–Ω–∏—è / 400–º–ª\n",
      "\n",
      "3. Score: 1.0000\n",
      "   Competitor: –®–ê–ú–ü–£–ù–¨ Elseve –¥–ª—è –æ–∫—Ä–∞—à–µ–Ω–Ω—ã—Ö –≤–æ–ª–æ—Å 250–º–ª\n",
      "   Our:        –¥–ª—è –æ–∫—Ä–∞—à–µ–Ω–Ω—ã—Ö –≤–æ–ª–æ—Å –ó–∞—Å—ñ–± –¥–ª—è –º–∏—Ç—Ç—è –≤–æ–ª–æ—Å—Å—è Elseve 250–º–ª\n",
      "\n",
      "4. Score: 1.0000\n",
      "   Competitor: –®–ê–ú–ü–£–ù–¨ SCHAUMA \"–¥–ª—è –º—É–∂—á–∏–Ω\" 400–º–ª\n",
      "   Our:        –¥–ª—è –º—É–∂—á–∏–Ω –®–∞–º–ø—É–Ω—å –¥–ª—è –≤–æ–ª–æ—Å—Å—è SCHAUMA 400–º–ª\n",
      "\n",
      "5. Score: 1.0000\n",
      "   Competitor: –®–∞–º–ø—É–Ω—å –¥/–≤–æ–ª–æ—Å –®–∞—É–º–∞ (fresh it up) 250–º–ª\n",
      "   Our:        –®–∞—É–º–∞ | SHAMPOO | fresh it up | 250–º–ª\n"
     ]
    }
   ],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑\n",
    "stats = matcher.analyze_results(results, show_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Results saved to: results_gpu_matched.csv\n"
     ]
    }
   ],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "results.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "print(f\"üíæ Results saved to: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitor_index</th>\n",
       "      <th>competitor_product</th>\n",
       "      <th>our_index</th>\n",
       "      <th>our_product</th>\n",
       "      <th>retrieval_score</th>\n",
       "      <th>rerank_score</th>\n",
       "      <th>retrieval_rank</th>\n",
       "      <th>match_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>–•—ç–¥ —ç–Ω–¥ –®–æ–ª–¥–µ—Ä—Å - –®–∞–º–ø—É–Ω—å –¥/–≤–æ–ª–æ—Å –ø—Ä–æ—Ç–∏–≤ –ø–µ—Ä—Ö–æ...</td>\n",
       "      <td>183</td>\n",
       "      <td>SHAMPOO [H&amp;S] –ø—Ä–æ—Ç–∏–≤ –ø–µ—Ä—Ö–æ—Ç–∏ (400–º–ª)</td>\n",
       "      <td>0.795066</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>1</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Head &amp; Shoulders –ó–∞—Å—ñ–± –¥/–≤–æ–ª–æ—Å—Å—è –º–µ–Ω—Ç–æ–ª 200–º–ª</td>\n",
       "      <td>387</td>\n",
       "      <td>Hair cleanser Head&amp;Shoulders - –º–µ–Ω—Ç–æ–ª / 200–º–ª</td>\n",
       "      <td>0.882091</td>\n",
       "      <td>0.998047</td>\n",
       "      <td>1</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Head&amp;Shoulders - –®–∞–º–ø. –¥–ª—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ–∂–∏...</td>\n",
       "      <td>35</td>\n",
       "      <td>Hair cleanser [Head&amp;Shoulders] –¥–ª—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å...</td>\n",
       "      <td>0.889190</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>1</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Pantene ProV - –ó–∞—Å—ñ–± –¥/–≤–æ–ª–æ—Å—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ,...</td>\n",
       "      <td>438</td>\n",
       "      <td>Hair cleanser [–ü–∞–Ω—Ç–∏–Ω] –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ (400–º–ª)</td>\n",
       "      <td>0.779750</td>\n",
       "      <td>0.989258</td>\n",
       "      <td>1</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pantene ProV –®–∞–º–ø—É–Ω—å –æ–±—ä–µ–º 250–º–ª</td>\n",
       "      <td>39</td>\n",
       "      <td>Pantene Pro-V Shamp –æ–±—ä–µ–º 250–º–ª</td>\n",
       "      <td>0.876570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>–®–∞–º–ø. Pantene (–ø–∏—Ç–∞–Ω–∏–µ) 200–º–ª</td>\n",
       "      <td>10</td>\n",
       "      <td>–ø–∏—Ç–∞–Ω–∏–µ Shamp Pantene 200–º–ª</td>\n",
       "      <td>0.922740</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>1</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>L'Oreal Elseve –®–ê–ú–ü–£–ù–¨ –ø—Ä–æ—Ç–∏–≤ –≤—ã–ø–∞–¥–µ–Ω–∏—è 400–º–ª</td>\n",
       "      <td>18</td>\n",
       "      <td>Shamp –≠–ª—å—Å–µ–≤ - –ø—Ä–æ—Ç–∏–≤ –≤—ã–ø–∞–¥–µ–Ω–∏—è / 400–º–ª</td>\n",
       "      <td>0.819458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>–®–ê–ú–ü–£–ù–¨ Elseve –¥–ª—è –æ–∫—Ä–∞—à–µ–Ω–Ω—ã—Ö –≤–æ–ª–æ—Å 250–º–ª</td>\n",
       "      <td>82</td>\n",
       "      <td>–¥–ª—è –æ–∫—Ä–∞—à–µ–Ω–Ω—ã—Ö –≤–æ–ª–æ—Å –ó–∞—Å—ñ–± –¥–ª—è –º–∏—Ç—Ç—è –≤–æ–ª–æ—Å—Å—è E...</td>\n",
       "      <td>0.927136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>–ó–∞—Å—ñ–± –¥/–≤–æ–ª–æ—Å—Å—è L'Oreal Elseve (—ç–∫—Å—Ç—Ä–∞–æ—Ä–¥–∏–Ω–∞—Ä–Ω...</td>\n",
       "      <td>219</td>\n",
       "      <td>–®–∞–º–ø—É–Ω—å –¥–ª—è –≤–æ–ª–æ—Å—Å—è [Elseve L'Oreal] —ç–∫—Å—Ç—Ä–∞–æ—Ä–¥...</td>\n",
       "      <td>0.938586</td>\n",
       "      <td>0.997559</td>\n",
       "      <td>1</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Gliss –®–∞–º–ø. —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ 400–º–ª</td>\n",
       "      <td>332</td>\n",
       "      <td>–ì–ª–∏—Å—Å –ö—É—Ä | –®–∞–º–ø—É–Ω—å –¥–ª—è –≤–æ–ª–æ—Å—Å—è | —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ...</td>\n",
       "      <td>0.843782</td>\n",
       "      <td>0.996582</td>\n",
       "      <td>2</td>\n",
       "      <td>matched</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   competitor_index                                 competitor_product  \\\n",
       "0                 0  –•—ç–¥ —ç–Ω–¥ –®–æ–ª–¥–µ—Ä—Å - –®–∞–º–ø—É–Ω—å –¥/–≤–æ–ª–æ—Å –ø—Ä–æ—Ç–∏–≤ –ø–µ—Ä—Ö–æ...   \n",
       "1                 1      Head & Shoulders –ó–∞—Å—ñ–± –¥/–≤–æ–ª–æ—Å—Å—è –º–µ–Ω—Ç–æ–ª 200–º–ª   \n",
       "2                 2  Head&Shoulders - –®–∞–º–ø. –¥–ª—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ–∂–∏...   \n",
       "3                 3  Pantene ProV - –ó–∞—Å—ñ–± –¥/–≤–æ–ª–æ—Å—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ,...   \n",
       "4                 4                   Pantene ProV –®–∞–º–ø—É–Ω—å –æ–±—ä–µ–º 250–º–ª   \n",
       "5                 5                      –®–∞–º–ø. Pantene (–ø–∏—Ç–∞–Ω–∏–µ) 200–º–ª   \n",
       "6                 6      L'Oreal Elseve –®–ê–ú–ü–£–ù–¨ –ø—Ä–æ—Ç–∏–≤ –≤—ã–ø–∞–¥–µ–Ω–∏—è 400–º–ª   \n",
       "7                 7          –®–ê–ú–ü–£–ù–¨ Elseve –¥–ª—è –æ–∫—Ä–∞—à–µ–Ω–Ω—ã—Ö –≤–æ–ª–æ—Å 250–º–ª   \n",
       "8                 8  –ó–∞—Å—ñ–± –¥/–≤–æ–ª–æ—Å—Å—è L'Oreal Elseve (—ç–∫—Å—Ç—Ä–∞–æ—Ä–¥–∏–Ω–∞—Ä–Ω...   \n",
       "9                 9     Gliss –®–∞–º–ø. —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ 400–º–ª   \n",
       "\n",
       "   our_index                                        our_product  \\\n",
       "0        183               SHAMPOO [H&S] –ø—Ä–æ—Ç–∏–≤ –ø–µ—Ä—Ö–æ—Ç–∏ (400–º–ª)   \n",
       "1        387      Hair cleanser Head&Shoulders - –º–µ–Ω—Ç–æ–ª / 200–º–ª   \n",
       "2         35  Hair cleanser [Head&Shoulders] –¥–ª—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å...   \n",
       "3        438      Hair cleanser [–ü–∞–Ω—Ç–∏–Ω] –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ (400–º–ª)   \n",
       "4         39                    Pantene Pro-V Shamp –æ–±—ä–µ–º 250–º–ª   \n",
       "5         10                        –ø–∏—Ç–∞–Ω–∏–µ Shamp Pantene 200–º–ª   \n",
       "6         18            Shamp –≠–ª—å—Å–µ–≤ - –ø—Ä–æ—Ç–∏–≤ –≤—ã–ø–∞–¥–µ–Ω–∏—è / 400–º–ª   \n",
       "7         82  –¥–ª—è –æ–∫—Ä–∞—à–µ–Ω–Ω—ã—Ö –≤–æ–ª–æ—Å –ó–∞—Å—ñ–± –¥–ª—è –º–∏—Ç—Ç—è –≤–æ–ª–æ—Å—Å—è E...   \n",
       "8        219  –®–∞–º–ø—É–Ω—å –¥–ª—è –≤–æ–ª–æ—Å—Å—è [Elseve L'Oreal] —ç–∫—Å—Ç—Ä–∞–æ—Ä–¥...   \n",
       "9        332  –ì–ª–∏—Å—Å –ö—É—Ä | –®–∞–º–ø—É–Ω—å –¥–ª—è –≤–æ–ª–æ—Å—Å—è | —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ...   \n",
       "\n",
       "   retrieval_score  rerank_score  retrieval_rank match_status  \n",
       "0         0.795066      0.999512               1      matched  \n",
       "1         0.882091      0.998047               1      matched  \n",
       "2         0.889190      0.999512               1      matched  \n",
       "3         0.779750      0.989258               1      matched  \n",
       "4         0.876570      1.000000               1      matched  \n",
       "5         0.922740      0.999512               1      matched  \n",
       "6         0.819458      1.000000               1      matched  \n",
       "7         0.927136      1.000000               1      matched  \n",
       "8         0.938586      0.997559               1      matched  \n",
       "9         0.843782      0.996582               2      matched  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü—Ä–µ–≤—å—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Clearing models...\n",
      "   GPU memory: 2.28 GB\n",
      "‚úÖ Cleared\n"
     ]
    }
   ],
   "source": [
    "# –û—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏ (–∑–∞–ø—É—Å–∫–∞–π –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã)\n",
    "ProductMatcherGPU.clear_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
